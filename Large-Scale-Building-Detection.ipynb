{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large-Scale Building Detection\n",
    "\n",
    "We would like to find all of the buildings in a 20,000km2 region over Nigeria and Cameroon. To do so we chip out training and target AOIs from a mosaic of images spanning the region of interest using the [chip-from-vrt](https://github.com/PlatformStories/chip-from-vrt) task. Next we train a model to classify chips as 'Buildings' or 'No Buildings' using [train-cnn-chip-classifier](https://github.com/PlatformStories/train-cnn-chip-classifier), and deploy the model over the entire mosaic using [deploy-cnn-chip-classifier](https://github.com/PlatformStories/deploy-cnn-chip-classifier).\n",
    "\n",
    "Create a GBDX interface using [gbdxtools](https://github.com/digitalglobe/gbdxtools). You need your credentials to do this; you can find them under your profile on gbdx.geobigdata.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, uuid\n",
    "from os.path import join\n",
    "os.environ['GBDX_USERNAME'] = \n",
    "os.environ['GBDX_PASSWORD'] = \n",
    "os.environ['GBDX_CLIENT_ID'] = \n",
    "os.environ['GBDX_CLIENT_SECRET'] = \n",
    "\n",
    "import gbdxtools\n",
    "gbdx = gbdxtools.Interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the AWS credentials associated with this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session_info = gbdx.s3.info\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = session_info['S3_access_key']\n",
    "os.environ['AWS_SECRET_KEY'] = session_info['S3_secret_key']\n",
    "os.environ['AWS_SESSION_TOKEN'] = session_info['S3_session_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the location of input files and where to save outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_location = 's3://gbd-customer-data/58600248-2927-4523-b44b-5fec3d278c09/platform-stories/building-detection-large-scale'\n",
    "\n",
    "# Generate output location\n",
    "random_str = str(uuid.uuid4())\n",
    "output_location = join('platform-stories/trial-runs', random_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chip training data from the imagery using chip-from-vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_chip = gbdx.Task('chip-from-vrt')\n",
    "train_chip.inputs.geojson = join(input_location, 'train-geojson')\n",
    "train_chip.inputs.images = join(input_location, 'mosaic')\n",
    "train_chip.inputs.mosaic = 'True'\n",
    "train_chip.inputs.aws_access_key = os.environ['AWS_ACCESS_KEY_ID']\n",
    "train_chip.inputs.aws_secret_key = os.environ['AWS_SECRET_KEY']\n",
    "train_chip.inputs.aws_session_token = os.environ['AWS_SESSION_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using the output of the train_chip task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = gbdx.Task('train-cnn-chip-classifier')\n",
    "train.inputs.chips = train_chip.outputs.chips.value\n",
    "train.inputs.max_side_dim = '260'\n",
    "train.inputs.resize_dim = '150'\n",
    "train.inputs.classes = 'No Buildings, Buildings'\n",
    "train.inputs.train_size = '5000'\n",
    "train.inputs.nb_epoch = '50'\n",
    "train.inputs.test = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a workflow to chip out labeled training data and train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'4542571739720742321'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wf = gbdx.Workflow([train_chip, train])\n",
    "\n",
    "# Save workflow outputs\n",
    "train_wf.savedata(train_chip.outputs.chips, join(output_location, 'train-chips'))\n",
    "train_wf.savedata(train.outputs.trained_model, join(output_location, 'trained-model'))\n",
    "\n",
    "# Execute the workflow\n",
    "train_wf.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model is training we can chip all target AOIs from the mosaic. There are about 1,200,000 chips to extract, so we do this part in parallel to speed up the process. Each chip task will produce 100,000 target chips. Each target geojson is in a numbered directory in the input location, so we will loop through all 13 and create chip-from-vrt tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_chip_tasks = []\n",
    "\n",
    "# Create tasks for each target geojson\n",
    "for i in range(1,14):\n",
    "    target_task = gbdx.Task('chip-from-vrt')\n",
    "    target_task.inputs.geojson = join(input_location, 'target-geojsons', str(i))\n",
    "    target_task.inputs.images = join(input_location, 'mosaic')\n",
    "    target_task.inputs.mosaic = 'True'\n",
    "    target_task.inputs.aws_access_key = os.environ['AWS_ACCESS_KEY_ID']\n",
    "    target_task.inputs.aws_secret_key = os.environ['AWS_SECRET_KEY']\n",
    "    target_task.inputs.aws_session_token = os.environ['AWS_SESSION_TOKEN']\n",
    "    target_task.domain = 'raid'\n",
    "    target_chip_tasks.append(target_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and execute workflows for each target chip task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_chip_wfs = []\n",
    "\n",
    "for i in range(len(target_chip_tasks)):\n",
    "    wf = gbdx.Workflow([target_chip_tasks[i]])\n",
    "    wf.savedata(target_chip_tasks[i].outputs.chips, join(output_location, 'target-chips', str(i+1)))\n",
    "    target_chip_wfs.append(wf)\n",
    "    \n",
    "# Execute all workflows\n",
    "for i in target_chip_wfs:\n",
    "    i.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all workflows have completed we can deploy our model on the entire mosaic using the outputs of target_chip_wfs and train_wf. For the purpose of this demo we provide a sample trained model and target chips in the following locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep_tasks, dep_wfs = [],[]\n",
    "\n",
    "# Loop thorugh all batches of target chips\n",
    "for i in range(1,2):\n",
    "    dep_task = gbdx.Task('deploy-cnn-chip-classifier')\n",
    "    dep_task.inputs.model = join(input_location, 'trained-model')\n",
    "    dep_task.inputs.max_side_dim = '260'\n",
    "    dep_task.inputs.chips = join(input_location, 'target-chips', str(i))\n",
    "    dep_tasks.append(dep_task)\n",
    "    \n",
    "# Create a workflow for each task\n",
    "for i in range(len(dep_tasks)):\n",
    "    wf = gbdx.Workflow([dep_tasks[i]])\n",
    "    wf.savedata(dep_tasks[i].outputs.classified_geojson, join(output_location, 'deploy-results', str(i+1)))\n",
    "    dep_wfs.append(wf)\n",
    "    \n",
    "# Execute each workflow\n",
    "for i in dep_wfs:\n",
    "    i.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once complete you can combine the outputs of the deploy workflows to get a final classified geojson. Below is a sample output overlaid on the original imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1600\"\n",
       "            height=\"800\"\n",
       "            src=\"clip-grid-buildings-5000.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f7060348e90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('clip-grid-buildings-5000.html', width=1600, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
