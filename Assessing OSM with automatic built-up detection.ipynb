{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use GBDX to obtain a bird's eye view of the degree of completeness of [OpenStreetMap (OSM)](https://www.openstreetmap.org) building footprints in different cities around the world. The goal is to use this information to intelligently direct mappers where they are most needed.\n",
    "\n",
    "The idea is to run our unsupervised Land Use Land Cover (LULC) classification algorithm over these regions in order to identify built-up areas, then overlay the results of the algorithm with existing OSM building footprints and compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GBDX interface using gbdxtools. You need your credentials to do this; you can find them under your profile on [gbdx.geobigdata.io](https://gbdx.geobigdata.io/login)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GBDX_USERNAME'] = \n",
    "os.environ['GBDX_PASSWORD'] = \n",
    "os.environ['GBDX_CLIENT_ID'] =  \n",
    "os.environ['GBDX_CLIENT_SECRET'] = \n",
    "\n",
    "import gbdxtools\n",
    "gbdx = gbdxtools.Interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see an example of how our idea would work over a small urban area. \n",
    "We've picked a small WV02 multispectral chip from [here](https://github.com/platformstories/chips); keep in mind the LULC algorithm requires atmospherically compensated 8-band imagery. \n",
    "We've also picked the corresponding pansharpened chip for visualization purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms = 'urban_ms.tif'\n",
    "ps = 'urban_ps.tif'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mi\n",
    "%matplotlib inline\n",
    "import gdal\n",
    "import numpy as np\n",
    "\n",
    "def plot(plt, chip, band=None, color_map = 'Greys_r'):\n",
    "    \"Generic plotting function.\"\n",
    "    if color_map == 'rgb':\n",
    "        img = mi.imread(chip)\n",
    "        plt.imshow(img)\n",
    "    else:    \n",
    "        sample = gdal.Open(chip)\n",
    "        img = sample.ReadAsArray()\n",
    "        if band is not None: \n",
    "            img = img[band]\n",
    "        plt.imshow(img, cmap=color_map)\n",
    "\n",
    "# plot the pansharpened image and near-infrared-1 (NIR1) band in pseudocolor from the multispectral image\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(121)\n",
    "plot(plt, ps, color_map='rgb')\n",
    "plt.subplot(122)\n",
    "plot(plt, ms, band=2, color_map='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract an approximate built-up mask using the Protogen unsupervised LULC algorithm which classifies each pixel as water, vegetation, clouds, soil, shadows and unclassified. By exclusion, the last category approximately corresponds to materials like stone, cement and metal, which are used in buildings and roads. The following code produces the LULC classification and the unclassified mask for our example chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import protogen\n",
    "\n",
    "# create protogen interface object that derives lulc\n",
    "p1 = protogen.Interface('lulc','layers')\n",
    "p1.lulc.layers.name = 'lulc'\n",
    "p1.lulc.layers.visualization = 'rgb'\n",
    "\n",
    "# configure input\n",
    "p1.image = ms\n",
    "p1.image_config.bands = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "# execute\n",
    "p1.execute()\n",
    "\n",
    "# create\n",
    "p2 = protogen.Interface('lulc', 'masks')\n",
    "p2.lulc.masks.type = 'single'\n",
    "\n",
    "# mask settings\n",
    "p2.lulc.masks.switch_unclassified = True      \n",
    "p2.lulc.masks.switch_water = False   \n",
    "p2.lulc.masks.switch_vegetation = False \n",
    "p2.lulc.masks.switch_clouds = False \n",
    "p2.lulc.masks.switch_bare_soil = False \n",
    "p2.lulc.masks.switch_shadows = False \n",
    "p2.lulc.masks.switch_no_data = False \n",
    "\n",
    "# configure input\n",
    "p2.image = ms\n",
    "p2.image_config.bands = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "p2.execute()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(131)\n",
    "plot(plt, 'urban_ps.tif', color_map='rgb')\n",
    "plt.subplot(132)\n",
    "plot(plt, p1.output, color_map='rgb')\n",
    "plt.subplot(133)\n",
    "plot(plt, p2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From left to right we have the pansharpened chip, the LULC classification output (with green, brown, blue and grey indicating vegetation, soil, water and unclassified, respectively) and the unclassified mask. The mask highlights the built-up area quite nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many OSM buildings are in this chip? First we need to get its bounding box in lat, long coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "sample = rasterio.open(ms)\n",
    "\n",
    "# projection info\n",
    "print sample.crs\n",
    "\n",
    "# bounding box\n",
    "W, S, E, N = sample.bounds\n",
    "bbox = W, S, E, N\n",
    "\n",
    "print bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this bounding box to query the [OSM Overpass API](http://wiki.openstreetmap.org/wiki/Overpass_API) for buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import subprocess\n",
    "\n",
    "with open('buildings.osm', 'w') as f:\n",
    "    r = requests.get(url='http://www.overpass-api.de/api/xapi_meta?*[building=yes][bbox=' + ','.join(map(str, bbox)) + ']')\n",
    "    f.write(r.text.encode('ascii','ignore'))\n",
    "    \n",
    "convert = \"ogr2ogr -f GeoJSON buildings.geojson buildings.osm multipolygons\"\n",
    "proc = subprocess.Popen([convert], shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "out, err = proc.communicate()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then plot them on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ipyleaflet import Map, GeoJSON\n",
    "from shapely.geometry import shape\n",
    "\n",
    "with open('buildings.geojson') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for feature in data['features']:\n",
    "    feature['properties']['style'] = {'fillOpacity':0.2}\n",
    "\n",
    "g = GeoJSON(data=data)\n",
    "    \n",
    "m = Map(center=[(N+S)/2, (W+E)/2], zoom=16, height = '650px')\n",
    "\n",
    "m.add_layer(g)    \n",
    "    \n",
    "# launch map    \n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things are clear. This chip is somewhere in Japan (Osaka!) and that quite a few buildings are missing from OSM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple experiment indicates that using the LULC algorithm can indeed point us to unmapped buildings in OSM. We will test our idea on a number of cities around the world. The following images were picked at [discover.digitalglobe.com](https://discover.digitalglobe.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# catalog id and center for each city\n",
    "\n",
    "cat_ids = {'nyc':         '104001001DB7BA00',\n",
    "           'houston':     '104001001838A000',\n",
    "           'la':          '104001001EBB4400', \n",
    "           'montreal':    '1040010023BEFD00', \n",
    "           'athens':      '104001001B6E1400', \n",
    "           'madrid':      '1040010019852500', \n",
    "           'nairobi':     '103001005C7E5400', \n",
    "           'amman':       '103001003E6FFC00', \n",
    "           'santiago':    '1040010029467C00',\n",
    "           'bangkok':     '1030010063748E00',\n",
    "           'cairo':       '1030010063AFF100',\n",
    "           'osaka':       '10300100643CAC00',\n",
    "           'buenosaires': '103001006414E800',\n",
    "           'shanghai':    '1030010049993B00',\n",
    "           'tehran':      '103001005ED0D000',\n",
    "           'asuncion':    '103001005A8A6400',\n",
    "           'ulaanbaatar': '103001005F575800',\n",
    "           'perth':       '104001001D365400' }\n",
    "\n",
    "centers = {'nyc':         [40.71, -74.01],\n",
    "           'houston':     [29.76, 95.37],\n",
    "           'la':          [34.05, -118.24],\n",
    "           'montreal':    [45.50, -73.56],\n",
    "           'athens':      [37.98, 23.73],\n",
    "           'madrid':      [40.42, -3.70],\n",
    "           'nairobi':     [-1.29, 36.82],\n",
    "           'amman':       [31.95, 35.93],\n",
    "           'santiago':    [33.45, -70.67],\n",
    "           'bangkok':     [13.76, 100.50],\n",
    "           'cairo':       [30.04, 31.24],\n",
    "           'osaka':       [34.69, 135.50],\n",
    "           'buenosaires': [-34.60, -58.38],\n",
    "           'shanghai':    [31.23, 121.47],      \n",
    "           'tehran':      [35.69, 51.39],\n",
    "           'asuncion':    [-25.26, 57.58],\n",
    "           'ulaanbaatar': [47.89, 106.91],\n",
    "           'perth':       [-31.95, 115.86]}\n",
    "\n",
    "cities = cat_ids.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each catalog id, we run a GBDX workflow which orders the raw image from the DG factory and then produces an orthorectified, atmospherically compensated 8-band image using the [AOP_Strip_Processor](http://gbdxdocs.digitalglobe.com/docs/advanced-image-preprocessor). Once the workflows complete, the images are stored under platform-stories/osm-lulc/images. This is a time-consuming step which you can skip as we've already run it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_location = 'platform-stories/osm-lulc/images'   # where to save the images\n",
    "wf_ids = {}\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "for city in cities:\n",
    "    \n",
    "    # create order task\n",
    "    # it the images are not on GBDX, this task will order them from the DG factory\n",
    "    order = gbdx.Task('Auto_Ordering')\n",
    "    order.inputs.cat_id = cat_ids[city]\n",
    "    order.impersonation_allowed = True\n",
    "\n",
    "    # run orthorectification and acomp\n",
    "    aop_ms = gbdx.Task('AOP_Strip_Processor')\n",
    "    aop_ms.inputs.data = order.outputs.s3_location.value\n",
    "    aop_ms.inputs.bands = 'MS'\n",
    "    aop_ms.inputs.enable_acomp = True\n",
    "    aop_ms.inputs.enable_pansharpen = False\n",
    "    aop_ms.inputs.enable_dra = False\n",
    "\n",
    "    # define preprocessing workflow\n",
    "    wf = gbdx.Workflow([order, aop_ms])\n",
    "\n",
    "    # set output location \n",
    "    wf.savedata(aop_ms.outputs.data, join(output_location, city))\n",
    "\n",
    "    # execute\n",
    "    wf_ids[city] = wf.execute()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check status of workflows    \n",
    "for city in cities:\n",
    "    wf = gbdx.Workflow([])\n",
    "    wf.id = wf_ids[city]\n",
    "    print city, wf.id, wf.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect each of these images in full resolution and draw bounding boxes of the areas in which we are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, TileLayer, DrawControl\n",
    "from shapely.geometry import shape\n",
    "import sys\n",
    "\n",
    "cat_id = cat_ids['asuncion']\n",
    "\n",
    "# get tms url and bounding box for each idaho image corresponding to this catid\n",
    "urls, bboxes = gbdx.idaho.get_tms_layers(cat_id)\n",
    "\n",
    "# center the map based on idaho image bounds\n",
    "center = [sum(x)/len(x) for x in zip(*[((N+S)/2.0, (W+E)/2.0) for (W,S,E,N) in bboxes])]\n",
    "\n",
    "m = Map(center=center, zoom=10, height='800px')\n",
    "\n",
    "# add idaho images\n",
    "for url in urls:\n",
    "    m.add_layer(TileLayer(url=url))\n",
    "\n",
    "# enable rectangle draw\n",
    "dc = DrawControl(polygon={'shapeOptions': {'color': '#00f5FF'}}, polyline={})\n",
    "def handle_draw(self, action, geo_json):\n",
    "    geom = shape(geo_json['geometry'])\n",
    "    print 'W, S, E, N = %s\\n' % (str(geom.bounds))    \n",
    "dc.on_draw(handle_draw)\n",
    "m.add_control(dc)    \n",
    "    \n",
    "# launch map    \n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some sample bounding boxes which we've drawn arbitrarily over each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bboxes = {'nyc': (-73.95632922649384, 40.67078428278468, -73.89315783977509, 40.74625719581601),\n",
    "          'houston': (-95.13090491294861, 29.719047995031016, -94.99769568443298, 29.901953768885594),\n",
    "          'la': (-118.32255542278288, 34.15873756789489, -118.17252337932585, 34.28251185970165),\n",
    "          'montreal': (-73.68750751018524, 45.62199932750296, -73.52236926555634, 45.755584499516516),\n",
    "          'athens': (23.63831341266632, 38.01784624197521, 23.791778683662415, 38.11515296145808),\n",
    "          'madrid': (-3.7636488676071167, 40.451429341017324, -3.6263197660446167, 40.5083584870881),\n",
    "          'nairobi': (36.73872381448745, -1.3279983315316601, 36.88343435525894, -1.242017618358388),\n",
    "          'amman': (35.79846203327179, 31.888389626458963, 35.97424328327179, 32.043632232381455),\n",
    "          'santiago': (-70.74042499065399, -33.45030473839097, -70.58936297893524, -33.3886947889702),\n",
    "          'bangkok': (100.44030010700226, 13.575965977708762, 100.5965119600296, 13.671059968841831),\n",
    "          'cairo': (31.244285702705383, 30.045368026249772, 31.349342465400696, 30.11874679593054),\n",
    "          'osaka': (135.4063493013382, 34.598781325037756, 135.48188030719757, 34.712028818736535),\n",
    "          'buenosaires': (-58.50621789693832, -34.67611297581835, -58.39000314474106, -34.596736825050044),\n",
    "          'shanghai': (121.50280773639678, 31.13559214758519, 121.60855114459991, 31.23486673223854),\n",
    "          'tehran': (51.29124462604522, 35.712275224230865, 51.481788754463196, 35.8234243437396),\n",
    "          'perth': (115.77790081501009, -31.958215741514543, 115.92449963092803, -31.80399586706599),\n",
    "          'ulaanbaatar': (106.72447979450226, 47.8784119735556, 106.93768322467804, 47.93939724053319),\n",
    "          'asuncion': (-57.67184436321258, -25.389250469786013, -57.524215579032905, -25.26729487165973)  \n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to deploy on GBDX. The following GBDX workflow does a few things:\n",
    "- Creates the built-up mask for each area of interest as a black-and-white tif image. This is done by passing the protogen Interface object we used in our little experiment as a string to the task [protogen-runner](https://github.com/PlatformStories/protogen-runner).\n",
    "- Downloads the OSM building footprints within the area of interest. We've created the task [download-osm-buildings](https://github.com/PlatformStories/download-osm-buildings) for this purpose, which outputs a geojson file with the building footprints. \n",
    "- Uploads the mask and the geojson to mapbox for visualization. We've created the task [upload-to-mapbox](https://github.com/PlatformStories/download-osm-buildings) for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import uuid\n",
    "from os.path import join\n",
    "\n",
    "wwf_ids = {}\n",
    "random_str = str(uuid.uuid4())\n",
    "\n",
    "# mapbox upload token\n",
    "mapbox_token = 'PUT VALID TOKEN HERE'\n",
    "\n",
    "# execute a workflow for each city\n",
    "for city in cities:    \n",
    "    \n",
    "    # configure extent of mask\n",
    "    bbox = bboxes[city]\n",
    "    W, S, E, N = bbox\n",
    "    p2.image_config.input_latlong_rectangle = [W, N, E, S]\n",
    "\n",
    "    # pass the protogen object to the protogen-runner task     \n",
    "    lulc_mask = gbdx.Task('protogen-runner')\n",
    "    lulc_mask.inputs.pickle = pickle.dumps(p2)\n",
    "    \n",
    "    # set the image input to the s3 location of the corresponding strip \n",
    "    lulc_mask.inputs.image = join('s3://gbd-customer-data/32cbab7a-4307-40c8-bb31-e2de32f940c2/platform-stories/osm-lulc/images', city)\n",
    "    \n",
    "    # download osm building footprints in bounding box\n",
    "    dob = gbdx.Task('download-osm-buildings')\n",
    "    dob.inputs.bbox = ','.join(map(str, bbox))\n",
    "\n",
    "    # upload results to mapbox\n",
    "    utom_mask = gbdx.Task('upload-to-mapbox')\n",
    "    utom_mask.inputs.input = lulc_mask.outputs.output.value\n",
    "    utom_mask.inputs.tileset_name = 'osm-lulc-ras-' + city \n",
    "    utom_mask.inputs.token = mapbox_token    \n",
    "    utom_footprints = gbdx.Task('upload-to-mapbox')\n",
    "    utom_footprints.inputs.input = dob.outputs.geojson.value\n",
    "    utom_footprints.inputs.tileset_name = 'osm-lulc-vec-' + city \n",
    "    utom_footprints.inputs.token = mapbox_token \n",
    "    \n",
    "    # execute the workflow and save data on s3\n",
    "    wf = gbdx.Workflow([lulc_mask, dob, utom_mask, utom_footprints])\n",
    "    output_location = join('platform-stories/trial-runs', random_str, city)\n",
    "    wf.savedata(lulc_mask.outputs.output, join(output_location, 'mask'))\n",
    "    wf.savedata(dob.outputs.geojson, join(output_location, 'geojson'))\n",
    "    wwf_ids[city] = wf.execute()\n",
    "    \n",
    "print join('platform-stories/trial-runs', random_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check status of workflows\n",
    "for city in cities:\n",
    "    wf = gbdx.Workflow([])\n",
    "    wf.id = wwf_ids[city]\n",
    "    print city, wf.id, wf.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check if your raster and vector tilesets have been successfully uploaded to mapbox at [https://www.mapbox.com/studio/tilesets/](https://www.mapbox.com/studio/tilesets/). We've created the following demo html page which references the tilesets. For each city, the built-up mask is shown in black-and-white and the buildings that we retrieved from the OSM Overpass API are shown in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('http://gbdxstories.digitalglobe.com/pages/osm-lulc/cities.html', width=1600, height=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
