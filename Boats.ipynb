{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order/preprocess imagery, run boat-detector and spaceknow_ship_segmentation and collect runtime statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set credentials\n",
    "\n",
    "import os\n",
    "os.environ['GBDX_USERNAME'] = ''\n",
    "os.environ['GBDX_PASSWORD'] = ''\n",
    "os.environ['GBDX_CLIENT_ID'] = '' \n",
    "os.environ['GBDX_CLIENT_SECRET'] = ''\n",
    "\n",
    "import gbdxtools\n",
    "gbdx = gbdxtools.Interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catids = ['1040050005DC6000',             # Sevastopol, WV03, 2017-08-09\n",
    "          '1030010070611600',             # Halifax, WV02, 2017-08-25\n",
    "          '104001002E7BBF00',             # Genoa, WV03, 2017-06-20  \n",
    "          '105001000A1FFF00',             # Osaka, GE01, 2017-06-03\n",
    "          '103001006100D200']             # Dubai, WV02, 2016-12-13\n",
    "\n",
    "from os.path import join\n",
    "          \n",
    "wfids = {}          \n",
    "          \n",
    "for catid in catids:          \n",
    "          \n",
    "    # order\n",
    "    order = gbdx.Task('Auto_Ordering', cat_id=catid)\n",
    "    order.impersonation_allowed = True\n",
    "\n",
    "    # acomped multispectral in utm\n",
    "    aop1 = gbdx.Task('AOP_Strip_Processor',\n",
    "                     data=order.outputs.s3_location.value,\n",
    "                     bands='MS',\n",
    "                     enable_dra=False,\n",
    "                     enable_pansharpen=False,\n",
    "                     ortho_epsg='UTM')     \n",
    "\n",
    "    # acomped pansharpened with baselayer matching in utm\n",
    "    # baselayer matching is optional but results in better colors\n",
    "    aop2 = gbdx.Task('AOP_Strip_Processor',\n",
    "                     data=order.outputs.s3_location.value,\n",
    "                     enable_dra=False,                      # disable automatic dra\n",
    "                     ortho_epsg='UTM')                         \n",
    "    blm = gbdx.Task('baselayermatch',\n",
    "                    data=aop2.outputs.data.value,\n",
    "                    cloud_id=catid)                        # take clouds into account when dra'ing\n",
    "\n",
    "    # acomped pansharpened per spaceknow settings\n",
    "    aop3 = gbdx.Task('AOP_Strip_Processor',\n",
    "                     data=order.outputs.s3_location.value,\n",
    "                     ortho_pixel_size='0.5',\n",
    "                     ortho_interpolation_type='Bilinear')      \n",
    "                    \n",
    "    # dsat boat detection\n",
    "    bd = gbdx.Task('boat-detector',\n",
    "                   ms_image=aop1.outputs.data.value,\n",
    "                   ps_image=blm.outputs.data.value)\n",
    "\n",
    "    # spaceknow boat detection\n",
    "    # crop in 4 parts - the spaceknow task works on small chunks\n",
    "    crop = gbdx.Task('CropGeotiff', data=aop3.outputs.data.value, num_partitions='4')                \n",
    "          \n",
    "    # each of the 4 parts goes to a separate spaceknow task\n",
    "    sss = [0]*4    \n",
    "    sss[0] = gbdx.Task('spaceknow_ship_segmentation', data=crop.outputs.data_0.value)\n",
    "    sss[1] = gbdx.Task('spaceknow_ship_segmentation', data=crop.outputs.data_1.value)\n",
    "    sss[2] = gbdx.Task('spaceknow_ship_segmentation', data=crop.outputs.data_2.value)\n",
    "    sss[3] = gbdx.Task('spaceknow_ship_segmentation', data=crop.outputs.data_3.value)\n",
    "      \n",
    "    wf = gbdx.Workflow([order, aop1, aop2, aop3, blm, bd, crop] + sss)\n",
    "    wf.savedata(aop1.outputs.data, join('platform-stories/boats', catid, 'ms'))\n",
    "    wf.savedata(blm.outputs.data, join('platform-stories/boats', catid, 'ps'))\n",
    "    wf.savedata(aop3.outputs.data, join('platform-stories/boats', catid, 'ps-sss'))\n",
    "    wf.savedata(bd.outputs.detections, join('platform-stories/boats/detections', catid))\n",
    "    for i in range(4):\n",
    "        wf.savedata(sss[i].outputs.result, join('platform-stories/boats/detections-sss', catid, str(i)))\n",
    "      \n",
    "    wfids[catid] = wf.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4675222631758838872 {u'state': u'complete', u'event': u'succeeded'}\n",
      "4675222606140016285 {u'state': u'complete', u'event': u'succeeded'}\n",
      "4675222645986135861 {u'state': u'complete', u'event': u'succeeded'}\n",
      "4675222659649856198 {u'state': u'complete', u'event': u'succeeded'}\n",
      "4675222593325639999 {u'state': u'complete', u'event': u'succeeded'}\n",
      "4675222618665250491 {u'state': u'complete', u'event': u'succeeded'}\n"
     ]
    }
   ],
   "source": [
    "for catid in wfids:\n",
    "    wf = gbdx.Workflow([])\n",
    "    wf.id = wfids[catid]\n",
    "    print wf.id, wf.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate waiting time and execution time per km2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boat-detector mean waiting time: 154.683333333 min\n",
      "boat-detector mean execution time: 0.0155878934591 min/km2\n",
      "spaceknow_ship_segmentation mean waiting time: 161.392361111 min\n",
      "spaceknow_ship_segmentation mean execution time: 0.781218699136 min/km2\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from shapely.wkt import loads\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "\n",
    "# get datetime object from string timestamp\n",
    "def get_time(timestamp):\n",
    "    return datetime.datetime.strptime(timestamp[:-13], \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# get area in km2 from wkt string (we need this for the execution time per km2 calculation)\n",
    "def area_km2(wkt):\n",
    "    shape = loads(wkt)\n",
    "    proj = partial(pyproj.transform, pyproj.Proj(init='epsg:4326'),\n",
    "                   pyproj.Proj('+proj=aea', lat1=shape.bounds[1], lat2=shape.bounds[3]))\n",
    "    return transform(proj, shape).area/float(10**6)\n",
    "\n",
    "submission_times, start_times, end_times, failures, wait_times, exec_times = {}, {}, {}, {} , {}, {}\n",
    "\n",
    "for task in ['boat-detector', 'spaceknow_ship_segmentation']:\n",
    "    submission_times[task] = {}\n",
    "    start_times[task] = {}\n",
    "    end_times[task] = {} \n",
    "    failures[task] = {}\n",
    "    wait_times[task] = []\n",
    "    exec_times[task] = []\n",
    "    \n",
    "for catid in wfids:\n",
    "    \n",
    "    # compute the area\n",
    "    wkt =  gbdx.catalog.get_strip_footprint_wkt(catid)\n",
    "    area = area_km2(wkt)\n",
    "    \n",
    "    wf = gbdx.Workflow([])\n",
    "    wf.id = wfids[catid]\n",
    "\n",
    "    for event in wf.events:\n",
    "\n",
    "        if 'boat-detector' in event['task'] or 'spaceknow_ship_segmentation' in event['task']:\n",
    "\n",
    "            if event['task'][0] == 'b':\n",
    "                task = 'boat-detector'\n",
    "            else:\n",
    "                task = 'spaceknow_ship_segmentation'\n",
    "            \n",
    "            task_id = event['task_id']\n",
    "            \n",
    "            failures[task][task_id] = False\n",
    "            \n",
    "            if event['event'] == 'submitted':\n",
    "                submission_times[task][task_id] = get_time(event['timestamp'])\n",
    "            elif event['event'] == 'started':\n",
    "                start_times[task][task_id] = get_time(event['timestamp'])\n",
    "            elif event['event'] == 'succeeded':\n",
    "                end_times[task][task_id] = get_time(event['timestamp'])\n",
    "            elif event['event'] == 'failed':\n",
    "                failures[task][task_id] = True\n",
    "    \n",
    "for task in ['boat-detector', 'spaceknow_ship_segmentation']:\n",
    "    \n",
    "    if task == 'spaceknow_ship_segmentation':\n",
    "        area_task = area/4.0\n",
    "    else:\n",
    "        area_task = area\n",
    "    \n",
    "    for task_id in submission_times[task]:\n",
    "    \n",
    "        wait_times[task].append((start_times[task][task_id] - submission_times[task][task_id]).total_seconds()/60)\n",
    "        if not failures[task][task_id]:\n",
    "            exec_times[task].append((end_times[task][task_id] - start_times[task][task_id]).total_seconds()/(60*area_task))\n",
    "    \n",
    "    print '{} mean waiting time: {} min'.format(task, np.mean(wait_times[task]))\n",
    "    print '{} mean execution time: {} min/km2'.format(task, np.mean(exec_times[task]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
