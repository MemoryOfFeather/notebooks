{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to count the number of oil tanks in Houston TX, a major global oil storage facility.  \n",
    "We'll look for images over the area of interest, download a small segment that contains oil tanks,\n",
    "and run some feature extraction experiments using PROTOGEN. \n",
    "When we are happy with our code, we'll deploy it as a GBDX task on the entirety of the area of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GBDX interface using [gbdxtools](https://github.com/digitalglobe/gbdxtools). You need your credentials to do this; you can find them under your profile on gbdx.geobigdata.io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GBDX_USERNAME'] = \n",
    "os.environ['GBDX_PASSWORD'] = \n",
    "os.environ['GBDX_CLIENT_ID'] =  \n",
    "os.environ['GBDX_CLIENT_SECRET'] = \n",
    "\n",
    "import gbdxtools\n",
    "gbdx = gbdxtools.Interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one of DigitalGlobe's material selection sites to explore the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://discover.digitalglobe.com', width=1600, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use gdbxtools (but it is less visually appealing ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find WorldView-3 PAN+MS imagery with low cloud cover\n",
    "filters = [\"sensorPlatformName = 'WORLDVIEW03'\",\n",
    "           \"cloudCover < 10\",\n",
    "           \"imageBands = 'Pan_MS1_MS2'\"]\n",
    "\n",
    "# Pick an address\n",
    "address = 'Houston, TX'\n",
    "results = gbdx.catalog.search_address(address=address,\n",
    "                              startDate=\"2016-01-01T00:00:00.000Z\",\n",
    "                              endDate=\"2016-11-01T00:00:00.000Z\",\n",
    "                              filters=filters)\n",
    "\n",
    "# Results is a dictionary with multiple entries. Each entry corresponds to an image over the area of interest.\n",
    "for result in results:\n",
    "    properties = result['properties']\n",
    "    print 'catid: ' + properties['catalogID']\n",
    "    print 'cloud cover: ' + properties['cloudCover']\n",
    "    print 'off nadir: ' + properties['offNadirAngle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick an image; the lowest the cloud cover and the off nadir angle, the better the quality of the results.\n",
    "We've selected 104001001838A000 (WV3, 2016).\n",
    "\n",
    "The following batch GBDX workflow orders the raw image from the DG factory, and then produces an orthorectified panchromatic image via the AOP_Strip_Processor. Once the workflow completes, the image is stored under platform-stories/oil-tanks/image-houston-pan. This is a time-consuming step which you can skip; we've run this workflow for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catid = '104001001838A000'\n",
    "\n",
    "# create order task\n",
    "# it the images are not on GBDX, this task will order them from the DG factory\n",
    "order = gbdx.Task('Auto_Ordering')\n",
    "order.inputs.cat_id = catid\n",
    "# for this particular task, we need to set this flag to true\n",
    "order.impersonation_allowed = True\n",
    "\n",
    "# panchromatic\n",
    "aop_pan = gbdx.Task('AOP_Strip_Processor')\n",
    "aop_pan.inputs.data = order.outputs.s3_location.value\n",
    "aop_pan.inputs.bands = 'PAN'\n",
    "aop_pan.inputs.enable_acomp = False\n",
    "aop_pan.inputs.enable_pansharpen = False\n",
    "aop_pan.inputs.enable_dra = False\n",
    "aop_pan.inputs.ortho_epsg='UTM'\n",
    "\n",
    "# define preprocessing workflow\n",
    "preprocess_wf = gbdx.Workflow([order, aop_pan])\n",
    "\n",
    "# set output location \n",
    "output_location = 'platform-stories/oil-tanks/image-houston'\n",
    "preprocess_wf.savedata(aop_pan.outputs.data, output_location + '-pan')\n",
    "\n",
    "# execute\n",
    "preprocess_wf.execute()\n",
    "preprocess_wf.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To inspect this image in full resolution, we'll create a leaflet map using the IDAHO TMS service (http://gbdxdocs.digitalglobe.com/docs/idaho-course) and ipyleaflet. \n",
    "We can draw a polygon on the map over a region of interest and get its bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, TileLayer, DrawControl\n",
    "from shapely.geometry import shape\n",
    "import sys\n",
    "\n",
    "catid = '104001001838A000'\n",
    "\n",
    "# get tms url and bounding box for each idaho image corresponding to this catid\n",
    "urls, bboxes = gbdx.idaho.get_tms_layers(catid)\n",
    "\n",
    "# center the map based on idaho image bounds\n",
    "center = [sum(x)/len(x) for x in zip(*[((N+S)/2.0, (W+E)/2.0) for (W,S,E,N) in bboxes])]\n",
    "\n",
    "m = Map(center=center, zoom=10)\n",
    "\n",
    "# add idaho images\n",
    "for url in urls:\n",
    "    m.add_layer(TileLayer(url=url))\n",
    "\n",
    "# enable rectangle draw\n",
    "dc = DrawControl(polygon={'shapeOptions': {'color': '#00f5FF'}}, polyline={})\n",
    "def handle_draw(self, action, geo_json):\n",
    "    geom = shape(geo_json['geometry'])\n",
    "    print 'W, S, E, N = %s\\n' % (str(geom.bounds))    \n",
    "dc.on_draw(handle_draw)\n",
    "m.add_control(dc)\n",
    "    \n",
    "# launch map    \n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the bounding box, we can use IDAHO to retrieve the corresponding image chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W, S, E, N = (-95.06904982030392, 29.7187207124839, -95.06123922765255, 29.723901202069023)\n",
    "chip_geo = 'houston_geo.tif'\n",
    "gbdx.idaho.get_chip(coordinates=[W, S, E, N], catid = catid, chip_type='PAN', filename=chip_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chip is in geographic projection, so it needs to be reprojected to UTM to minimize distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chip = 'houston_utm.tif'\n",
    "import utm\n",
    "easting, northing, utm_number, utm_letter = utm.from_latlon(S, W)\n",
    "reproject = \"gdalwarp -t_srs '+proj=utm +zone={} +datum=WGS84' -overwrite {} {}\".format(utm_number, chip_geo, chip)\n",
    "import subprocess\n",
    "proc = subprocess.Popen([reproject], shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "out, err = proc.communicate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the plot below. This will convince you why the UTM projection is important when performing morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define plotting functions\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import gdal\n",
    "\n",
    "def plot_one(chip):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sample = gdal.Open(chip)\n",
    "    img = sample.ReadAsArray()\n",
    "    plt.imshow(img, cmap='Greys_r')\n",
    "    \n",
    "def plot_two(chip1, chip2):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(121)\n",
    "    sample1 = gdal.Open(chip1)\n",
    "    img1 = sample1.ReadAsArray()\n",
    "    plt.imshow(img1, cmap='Greys_r')\n",
    "    plt.subplot(122)\n",
    "    sample2 = gdal.Open(chip2)\n",
    "    img2 = sample2.ReadAsArray()\n",
    "    plt.imshow(img2, cmap='Greys_r')\n",
    "\n",
    "plot_two(chip_geo, chip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use protogen extract module in order to detect the oil tanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import protogen\n",
    "\n",
    "e = protogen.Interface('extract', 'objects')\n",
    "e.extract.objects.type = 'tanks'\n",
    "e.extract.objects.visualization = 'binary'\n",
    "e.extract.objects.multiplier = 2.0\n",
    "e.extract.objects.dark_hole_size = 20          # remove holes with size < 20m2\n",
    "e.extract.objects.dark_line_radius = 1         # remove dark lines with radius < 1m\n",
    "e.extract.objects.bright_line_radius = 1       # remove bright lines with radius < 1m\n",
    "e.extract.objects.bright_patch_size = 20       # remove bright patches with size < 20m2\n",
    "e.image = chip\n",
    "\n",
    "e.athos.tree_type = 'max_tree'\n",
    "e.athos.area.usage = ['remove if outside']\n",
    "e.athos.area.min = [100.0]                     # keep nodes with area between min and max\n",
    "e.athos.area.max = [3500.0]\n",
    "e.athos.compactness.usage = ['remove if less'] # keep nodes with compactness greater than min\n",
    "e.athos.compactness.min = [0.97]\n",
    "e.athos.compactness.export = [1]\n",
    "\n",
    "# Execute PROTOGEN with the current configuration \n",
    "e.execute()\n",
    "\n",
    "plot_two(chip, e.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a new image containing just the oil tanks. We'll use the protogen vectorizer module to derive a geojson with the bounding boxes of the oil tanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = protogen.Interface('vectorizer', 'bounding_box')\n",
    "v.image = e.output\n",
    "v.vectorizer.bounding_box.filetype = 'geojson'\n",
    "v.vectorizer.bounding_box.target_bbox = False\n",
    "v.vectorizer.bounding_box.target_centroid = True\n",
    "v.vectorizer.bounding_box.processor = True\n",
    "v.athos.tree_type = 'union_find'                       \n",
    "v.athos.area.export = [1]\n",
    "v.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many vectors were extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(v.output) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "n_oil_tanks = len(data['features'])\n",
    "print 'There are ' + str(n_oil_tanks) + ' oil tanks in the area of interest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the vectors on the slippy map (you might need to scroll around to see them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add vectors\n",
    "from ipyleaflet import GeoJSON\n",
    "\n",
    "g = GeoJSON(data=data)\n",
    "\n",
    "# launch map\n",
    "m.add_layer(g)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now deploy our code on a large rectangle by 'taskifying' the extractor and the vectorizer and running a GBDX workflow.\n",
    "Taskification is accomplished by passing the protogen object as a pickled string to the protogen-runner task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define rectangle\n",
    "W, S, E, N = (-95.14483630657196, 29.696617936567343, -94.98828113079071, 29.773830057098092)\n",
    "e.image_config.input_latlong_rectangle = [W, N, E, S]\n",
    "\n",
    "import pickle\n",
    "\n",
    "def taskify(p):\n",
    "    \"Create instance of a GBDX task that runs a protogen.Interface() object p\"\n",
    "    t = gbdx.Task('protogen-runner')\n",
    "    t.inputs.pickle = pickle.dumps(p)\n",
    "    return t\n",
    "\n",
    "# Taskify protogen objects\n",
    "extract = taskify(e)\n",
    "vectorize = taskify(v)\n",
    "\n",
    "# Chain tasks: output port 'output' of extract task points to input port 'image' of vectorize task\n",
    "extract.inputs.image = 's3://gbd-customer-data/32cbab7a-4307-40c8-bb31-e2de32f940c2/platform-stories/oil-tanks/image-houston-pan'\n",
    "vectorize.inputs.image = extract.outputs.output.value\n",
    "\n",
    "# Define workflow\n",
    "wf = gbdx.Workflow([extract, vectorize])\n",
    "\n",
    "# Save extracted oil tank vectors\n",
    "import uuid\n",
    "from os.path import join\n",
    "random_str = str(uuid.uuid4())\n",
    "output_location = join('platform-stories/trial-runs', random_str)\n",
    "print output_location\n",
    "wf.savedata(extract.outputs.output, output_location)\n",
    "wf.savedata(vectorize.outputs.output, output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wf.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the workflow is complete, download the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbdx.s3.download(location=output_location, local_dir=random_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... count how many there are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# open geojson in directory\n",
    "with open(join(random_str, [x for x in os.listdir(random_str) if '.geojson' in x][0])) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "n_oil_tanks = len(data['features'])\n",
    "print 'There are ' + str(n_oil_tanks) + ' oil tanks in the area of interest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and add the vector layer on the slippy map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import GeoJSON\n",
    "\n",
    "g = GeoJSON(data=data)\n",
    "\n",
    "for feature in data['features']:\n",
    "    feature['properties']['style'] = {'fillOpacity':0}\n",
    "\n",
    "# launch map\n",
    "m.add_layer(g)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
